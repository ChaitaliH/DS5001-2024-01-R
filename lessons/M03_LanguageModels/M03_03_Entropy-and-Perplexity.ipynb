{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy and Peplexity -- NEEDS REVISION\n",
    "\n",
    "```yaml\n",
    "Course:  DS 5001\n",
    "Module:  03 Lab\n",
    "Topic:   Entropy and Peplexity\n",
    "Author:  R.C. Alvarado\n",
    "Purpose: Clarify concept of perplexity.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "\n",
    "**Entropy** $H$ is the expectation of information in a distribution.\n",
    "\n",
    "**Self-entropy** $h$ is the information of an event.\n",
    "\n",
    "**Information** $i$ is log normalized surprise of an event.\n",
    "\n",
    "**Surprise** $s$ is just the inverse probability on an event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability $p$\n",
    "\n",
    "$\\Large p = \\frac{n}{N}$\n",
    "\n",
    "$p(w) = \\Large\\frac{n_w}{N_{corpus}}$ \n",
    "\n",
    "`p = n / n.sum()`\n",
    "\n",
    "Most terms have low probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise $s$\n",
    "\n",
    "$\\Large s = \\Large\\frac{1}{p}$\n",
    "\n",
    "$s(w) = p(w)^{-1}$\n",
    "\n",
    "Surrprise $s$ increases as the inverse of $p$. Note how inverting $p$ adds variance to the long tail; the curve now looks like a simple quadratic. We can see a more gradual increase in surprise as terms become more rare.\n",
    "\n",
    "<!-- V.s.value_counts().plot(style='*-') -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information $i$\n",
    "\n",
    "$\\Large i= log_2(s)$\n",
    "\n",
    "$i(w) = log_2(s(w))$\n",
    "\n",
    "As normalized suprise, information now has a long tail structure. But notice also the range of information -- it is between 1 and 18. What does this correspond to?\n",
    "\n",
    "<!-- V.i.value_counts().plot(style='*-'); -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy $h$\n",
    "\n",
    "$\\Large h = p i$\n",
    "\n",
    "$h(w) = p(w)i(w)$\n",
    "\n",
    "For the self-entropy of each term, we multiply $p$ and $i$. When summed, this will give us the expectation of the information in the distribution, i.e. it's entropy.\n",
    "\n",
    "<!-- V.h.value_counts().plot(style='*-'); -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity $PP$\n",
    "\n",
    "<!-- $\\Large PP = \\Large 2^{i}$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chiasmus\n",
    "\n",
    "The process of computing entropy follows a chiasmus pattern.\n",
    "\n",
    "$A_1 \\rightarrow B_1 \\rightarrow B_2 \\rightarrow A_2$  \n",
    "\n",
    "<!--\n",
    "$p := A_1, s := B_1, i := B_2, h := A_2$\n",
    "-->\n",
    "\n",
    "$p \\rightarrow s \\rightarrow i \\rightarrow h$ \n",
    "\n",
    "$A: \\{p,h\\}$\n",
    "\n",
    "$B: \\{s,i\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "output_dir = config['DEFAULT']['output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohco = ['book_id','chap_num','para_num','sent_num','token_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = pd.read_csv(f\"{output_dir}/austen-combo-TOKENS-v2.csv\").set_index(ohco)\n",
    "V = pd.read_csv(f\"{output_dir}/austen-combo-VOCAB-v2.csv\").set_index('term_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dashwood</td>\n",
       "      <td>dashwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>had</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             token_str  term_str\n",
       "book_id chap_num para_num sent_num token_num                    \n",
       "1       1        1        0        0               The       the\n",
       "                                   1            family    family\n",
       "                                   2                of        of\n",
       "                                   3          Dashwood  dashwood\n",
       "                                   4               had       had"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>16.058901</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>17.643863</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>17.643863</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>17.643863</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>17.643863</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n  n_chars         p          i         h\n",
       "term_str                                           \n",
       "1         3        1  0.000015  16.058901  0.000235\n",
       "15        1        2  0.000005  17.643863  0.000086\n",
       "16        1        2  0.000005  17.643863  0.000086\n",
       "1760      1        4  0.000005  17.643863  0.000086\n",
       "1784      1        4  0.000005  17.643863  0.000086"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes language models have been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LM = {}\n",
    "for n in range(1, 4):\n",
    "    widx = [f\"w{i}\" for i in range(n)]\n",
    "    LM[n] = pd.read_csv(f\"{output_dir}/austen-combo-LM{n}-v2.csv\").set_index(widx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>16.239120</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>17.824082</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>17.824082</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>17.824082</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>17.824082</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>13.364651</td>\n",
       "      <td>0.001267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youthful</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>16.239120</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeal</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>15.016727</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealous</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>15.824082</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealously</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>16.824082</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8206 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            n         p          i         h\n",
       "w0                                          \n",
       "1           3  0.000013  16.239120  0.000210\n",
       "1760        1  0.000004  17.824082  0.000077\n",
       "1784        1  0.000004  17.824082  0.000077\n",
       "1785        1  0.000004  17.824082  0.000077\n",
       "1787        1  0.000004  17.824082  0.000077\n",
       "...        ..       ...        ...       ...\n",
       "youth      22  0.000095  13.364651  0.001267\n",
       "youthful    3  0.000013  16.239120  0.000210\n",
       "zeal        7  0.000030  15.016727  0.000453\n",
       "zealous     4  0.000017  15.824082  0.000273\n",
       "zealously   2  0.000009  16.824082  0.000145\n",
       "\n",
       "[8206 rows x 4 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPV = 2**V.h.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568.0405114200985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PPV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy and Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities of Sequences\n",
    "\n",
    "$ W = W_1^N = (w_1, w_2 ... w_N)$\n",
    "\n",
    "True distribution: $ p = p(W) $\n",
    "\n",
    "Model distribution: $ q = q(W) $\n",
    "\n",
    "### Cross Entropy\n",
    "\n",
    "$ H(p, q) = - \\sum_{x}^{} p(x) log_2(q(x)) $ \n",
    "\n",
    "$ H(p, q) = \\sum_{x}^{} p(x) log_2(\\frac{1}{q(x)}) $ \n",
    "\n",
    "$ i_q(x) = log_2(\\frac{1}{q(x)}) $\n",
    "\n",
    "$ H(p, q) = \\sum_{x} p(x) i_q(x) $ \n",
    "\n",
    "$ H(p, q) = \\vec{p} \\cdot \\vec{i_q} $\n",
    "\n",
    "### Cross Entropy relative to MaxEnt\n",
    "\n",
    "$ N = C(x) = \\sum_x c(x) $\n",
    "\n",
    "$ p_{u} = \\frac{1}{N} $ \n",
    "\n",
    "$ H_{cross} = H(p_u, q) $\n",
    "\n",
    "$ H_{cross} = \\sum_{x} \\frac{1}{N} i(x) $\n",
    "\n",
    "$ H_{cross} = \\frac{1}{N} \\sum_{x} i(x) $\n",
    "\n",
    "$ H_{cross} = \\frac{\\sum_x i(x)}{N} $\n",
    "\n",
    "$ H_{cross} = \\frac{ |\\vec{i}|_1 }{ N } $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity\n",
    "\n",
    "$ PP(W) = P(w_1, w_2 ... w_N)^{-1/N} $\n",
    "\n",
    "$ PP(p) = 2^{H(p)}$\n",
    "\n",
    "$ PP(p_u, q) = 2^{H_{cross}}$\n",
    "\n",
    "#### Redundancy\n",
    "\n",
    "$ H_{max} = log_2(N) $\n",
    "\n",
    "$ H_{max} = i(p_u) $\n",
    "\n",
    "$ R = 1 - \\frac{H}{H_{max}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From J & M\n",
    "<img src=\"perplexity.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Stack Overflow\n",
    "https://stats.stackexchange.com/questions/129352/how-to-find-the-perplexity-of-a-corpus\n",
    "<img src=\"stackover1.png\">\n",
    "<img src=\"stackover2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REDO**: See https://stackoverflow.com/questions/54941966/how-can-i-calculate-perplexity-using-nltk \n",
    "\n",
    "Perplexity is a measure of how well a probabilistic model is able to predict a sample. It is calculated as 2 to the power of the cross-entropy of the model and the sample. The lower the perplexity, the better the model is at predicting the sample.\n",
    "\n",
    "Here is an example of how to calculate perplexity in Python using the Natural Language Toolkit (NLTK):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist, MLEProbDist\n",
    "\n",
    "# sample text\n",
    "sample = \"This is a sample text for computing perplexity.\"\n",
    "\n",
    "# create a frequency distribution of the words in the sample\n",
    "fdist = FreqDist(sample.split())\n",
    "\n",
    "# create a maximum likelihood estimate (MLE) probability distribution\n",
    "mle = MLEProbDist(fdist)\n",
    "\n",
    "# calculate the perplexity of the sample using the MLE probability distribution\n",
    "perplexity = 2 ** -(sum(mle.logprob(word) for word in sample.split())/len(sample.split()))\n",
    "\n",
    "print(perplexity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the sample text is passed to the `FreqDist()` function to create a frequency distribution of the words in the sample. This frequency distribution is then passed to the `MLEProbDist()` function to create a maximum likelihood estimate probability distribution. Finally, the `logprob()` function is used to calculate the log probability of each word in the sample, and these probabilities are summed and divided by the number of words in the sample to calculate the cross-entropy. The perplexity is then calculated by raising 2 to the power of the negative of the cross-entropy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ChatGPT Jan 9 Version. Free Research Preview. Our goal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'This': 1, 'is': 1, 'a': 1, 'sample': 1, 'text': 1, 'for': 1, 'computing': 1, 'perplexity.': 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pp(sent_str):\n",
    "    \n",
    "    lang_mod = V.p\n",
    "    \n",
    "    tokens = set(sent_str.split()) \n",
    "    print(tokens)\n",
    "    \n",
    "    # x = set(tokens).intersection(V.index.values)\n",
    "    x = list(tokens.intersection(V.index.values))\n",
    "\n",
    "    print(x)\n",
    "    \n",
    "    mle = MLEProbDist(lang_mod.loc[x])\n",
    "    # print(mle)\n",
    "    # print(mle.freqdist())\n",
    "    # print(mle.generate())\n",
    "\n",
    "    print(mle._freqdist)\n",
    "\n",
    "    # sample = list(mle.samples())\n",
    "    # print(sample)\n",
    "    \n",
    "    # print(mle.logprob(sample[0]))\n",
    "\n",
    "\n",
    "    # # pp = 2 ** -(sum(mle.logprob(token) for token in tokens)/len(tokens))\n",
    "    # pp = 2 ** -(sum(mle.logprob(token) for token in sample)/len(sample))\n",
    "    # return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some paragraphs from Austen's _Emma_ and other stuff (first two)\n",
    "S_TEST = \"\"\"\n",
    "The car was brand new\n",
    "Computer programs are full of bugs\n",
    "The event had every promise of happiness for her friend \n",
    "Mr Weston was a man of unexceptionable character easy fortune suitable age and pleasant manners\n",
    "and there was some satisfaction in considering with what self-denying generous friendship she had always wished and promoted the match\n",
    "but it was a black morning's work for her \n",
    "The want of Miss Taylor would be felt every hour of every day \n",
    "She recalled her past kindness the kindness the affection of sixteen years \n",
    "how she had taught and how she had played with her from five years old \n",
    "how she had devoted all her powers to attach and amuse her in health \n",
    "and how nursed her through the various illnesses of childhood \n",
    "A large debt of gratitude was owing here \n",
    "but the intercourse of the last seven years \n",
    "the equal footing and perfect unreserve which had soon followed Isabella's marriage \n",
    "on their being left to each other was yet a dearer tenderer recollection \n",
    "She had been a friend and companion such as few possessed intelligent well-informed useful gentle \n",
    "knowing all the ways of the family \n",
    "interested in all its concerns \n",
    "and peculiarly interested in herself in every pleasure every scheme of hers \n",
    "one to whom she could speak every thought as it arose \n",
    "and who had such an affection for her as could never find fault \n",
    "How was she to bear the change \n",
    "It was true that her friend was going only half a mile from them \n",
    "but Emma was aware that great must be the difference between a Mrs Weston \n",
    "only half a mile from them \n",
    "and a Miss Taylor in the house \n",
    "and with all her advantages natural and domestic \n",
    "she was now in great danger of suffering from intellectual solitude \n",
    "She dearly loved her father \n",
    "but he was no companion for her \n",
    "He could not meet her in conversation rational or playful \n",
    "The evil of the actual disparity in their ages\n",
    "and Mr Woodhouse had not married early\n",
    "was much increased by his constitution and habits \n",
    "for having been a valetudinarian all his life \n",
    "without activity of mind or body \n",
    "he was a much older man in ways than in years \n",
    "and though everywhere beloved for the friendliness of his heart and his amiable temper \n",
    "his talents could not have recommended him at any time \n",
    "Her sister though comparatively but little removed by matrimony \n",
    "being settled in London only sixteen miles off was much beyond her daily reach \n",
    "and many a long October and November evening must be struggled through at Hartfield \n",
    "before Christmas brought the next visit from Isabella and her husband \n",
    "and their little children to fill the house and give her pleasant society again \n",
    "\"\"\".split('\\n')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of', 'Computer', 'full', 'bugs', 'programs', 'are'}\n",
      "['are', 'full', 'of']\n",
      "term_str\n",
      "are     0.001855\n",
      "full    0.000293\n",
      "of      0.030010\n",
      "Name: p, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_pp(S_TEST[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.p.loc[['the','cat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c3b963de08c47c3b6758389c5e0978ad73698a111eb508d4e16b558edb8f4cbf"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
